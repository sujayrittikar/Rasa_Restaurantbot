{
  "mood_unhappy": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 14,
    "confused_with": {}
  },
  "restaurant_search": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 18,
    "confused_with": {}
  },
  "location_cuisine": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8,
    "confused_with": {}
  },
  "bot_challenge": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "location": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 26,
    "confused_with": {}
  },
  "goodbye": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 21,
    "confused_with": {}
  },
  "order": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "get_address": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4,
    "confused_with": {}
  },
  "mood_great": {
    "precision": 0.9444444444444444,
    "recall": 0.9444444444444444,
    "f1-score": 0.9444444444444444,
    "support": 18,
    "confused_with": {
      "affirm": 1
    }
  },
  "deny": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 24,
    "confused_with": {}
  },
  "cuisine": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 19,
    "confused_with": {}
  },
  "get_menu": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "get_contact": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 17,
    "confused_with": {}
  },
  "get_order": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8,
    "confused_with": {}
  },
  "affirm": {
    "precision": 0.9411764705882353,
    "recall": 0.9411764705882353,
    "f1-score": 0.9411764705882353,
    "support": 17,
    "confused_with": {
      "mood_great": 1
    }
  },
  "accuracy": 0.9911504424778761,
  "macro avg": {
    "precision": 0.9928513071895425,
    "recall": 0.9928513071895425,
    "f1-score": 0.9928513071895425,
    "support": 226
  },
  "weighted avg": {
    "precision": 0.9911504424778761,
    "recall": 0.9911504424778761,
    "f1-score": 0.9911504424778761,
    "support": 226
  }
}